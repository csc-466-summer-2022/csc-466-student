{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Lab 3\n",
    "\n",
    "## Single Layer Neural Network, Evaluation, and Interpretation\n",
    "\n",
    "This lab is designed to teach you about different strategies for evaluating neural networks and interpreting the results. For this lab, we are going to study different methods for intrepreting a neural network. We are going to use a modified version of the perceptron learning algorithm. I have modified it to use the sigmoid activation function. This means our learning rule is updated. \n",
    "\n",
    "**Note:** Exercises can be autograded and count towards your lab and assignment score. Problems are graded for participation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path \n",
    "home = str(Path.home()) # all other paths are relative to this path. change to something else if this is not the case on your system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# make sure your run the cell above before running this\n",
    "import Lab3_helper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For developing this lab, we can use a Heart Disease factors dataset. Description of the data is found https://www.kaggle.com/datasets/kamilpytlak/personal-key-indicators-of-heart-disease."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HeartDisease</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoking</th>\n",
       "      <th>AlcoholDrinking</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>PhysicalHealth</th>\n",
       "      <th>MentalHealth</th>\n",
       "      <th>DiffWalking</th>\n",
       "      <th>Sex</th>\n",
       "      <th>AgeCategory</th>\n",
       "      <th>...</th>\n",
       "      <th>difficulty_walking_code</th>\n",
       "      <th>sex_code</th>\n",
       "      <th>age_category</th>\n",
       "      <th>race_code</th>\n",
       "      <th>diabetic_code</th>\n",
       "      <th>physical_activity_code</th>\n",
       "      <th>general_health_code</th>\n",
       "      <th>asthma_code</th>\n",
       "      <th>kidney_disease_code</th>\n",
       "      <th>skin_cancer_code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>No</td>\n",
       "      <td>16.60</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>No</td>\n",
       "      <td>Female</td>\n",
       "      <td>55-59</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>No</td>\n",
       "      <td>20.34</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>Female</td>\n",
       "      <td>80 or older</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No</td>\n",
       "      <td>26.58</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>No</td>\n",
       "      <td>Male</td>\n",
       "      <td>65-69</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No</td>\n",
       "      <td>24.21</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>No</td>\n",
       "      <td>Female</td>\n",
       "      <td>75-79</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>No</td>\n",
       "      <td>23.71</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Female</td>\n",
       "      <td>40-44</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  HeartDisease    BMI Smoking AlcoholDrinking Stroke  PhysicalHealth  \\\n",
       "0           No  16.60     Yes              No     No               3   \n",
       "1           No  20.34      No              No    Yes               0   \n",
       "2           No  26.58     Yes              No     No              20   \n",
       "3           No  24.21      No              No     No               0   \n",
       "4           No  23.71      No              No     No              28   \n",
       "\n",
       "   MentalHealth DiffWalking     Sex  AgeCategory  ... difficulty_walking_code  \\\n",
       "0            30          No  Female        55-59  ...                       0   \n",
       "1             0          No  Female  80 or older  ...                       0   \n",
       "2            30          No    Male        65-69  ...                       0   \n",
       "3             0          No  Female        75-79  ...                       0   \n",
       "4             0         Yes  Female        40-44  ...                       1   \n",
       "\n",
       "  sex_code age_category race_code  diabetic_code physical_activity_code  \\\n",
       "0        0            7         5              2                      1   \n",
       "1        0           12         5              0                      1   \n",
       "2        1            9         5              2                      1   \n",
       "3        0           11         5              0                      0   \n",
       "4        0            4         5              0                      1   \n",
       "\n",
       "  general_health_code asthma_code  kidney_disease_code  skin_cancer_code  \n",
       "0                   4           1                    0                 1  \n",
       "1                   4           0                    0                 0  \n",
       "2                   1           1                    0                 0  \n",
       "3                   2           0                    0                 1  \n",
       "4                   4           0                    0                 0  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "heartdisease_df = pd.read_csv(\n",
    "    f\"../data/heart_disease.csv\"\n",
    ")\n",
    "heartdisease_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to do some simple preprocessing before our neural network can deal with this data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BMI</th>\n",
       "      <th>PhysicalHealth</th>\n",
       "      <th>MentalHealth</th>\n",
       "      <th>SleepTime</th>\n",
       "      <th>smoking_code</th>\n",
       "      <th>alcohol_code</th>\n",
       "      <th>stroke_code</th>\n",
       "      <th>difficulty_walking_code</th>\n",
       "      <th>sex_code</th>\n",
       "      <th>age_category</th>\n",
       "      <th>...</th>\n",
       "      <th>GenHealth_Fair</th>\n",
       "      <th>GenHealth_Good</th>\n",
       "      <th>GenHealth_Poor</th>\n",
       "      <th>GenHealth_Very good</th>\n",
       "      <th>Asthma_No</th>\n",
       "      <th>Asthma_Yes</th>\n",
       "      <th>KidneyDisease_No</th>\n",
       "      <th>KidneyDisease_Yes</th>\n",
       "      <th>SkinCancer_No</th>\n",
       "      <th>SkinCancer_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.60</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.58</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>24.21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23.71</td>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     BMI  PhysicalHealth  MentalHealth  SleepTime  smoking_code  alcohol_code  \\\n",
       "0  16.60               3            30          5             1             0   \n",
       "1  20.34               0             0          7             0             0   \n",
       "2  26.58              20            30          8             1             0   \n",
       "3  24.21               0             0          6             0             0   \n",
       "4  23.71              28             0          8             0             0   \n",
       "\n",
       "   stroke_code  difficulty_walking_code  sex_code  age_category  ...  \\\n",
       "0            0                        0         0             7  ...   \n",
       "1            1                        0         0            12  ...   \n",
       "2            0                        0         1             9  ...   \n",
       "3            0                        0         0            11  ...   \n",
       "4            0                        1         0             4  ...   \n",
       "\n",
       "   GenHealth_Fair  GenHealth_Good  GenHealth_Poor  GenHealth_Very good  \\\n",
       "0               0               0               0                    1   \n",
       "1               0               0               0                    1   \n",
       "2               1               0               0                    0   \n",
       "3               0               1               0                    0   \n",
       "4               0               0               0                    1   \n",
       "\n",
       "   Asthma_No  Asthma_Yes  KidneyDisease_No  KidneyDisease_Yes  SkinCancer_No  \\\n",
       "0          0           1                 1                  0              0   \n",
       "1          1           0                 1                  0              1   \n",
       "2          0           1                 1                  0              1   \n",
       "3          1           0                 1                  0              0   \n",
       "4          1           0                 1                  0              1   \n",
       "\n",
       "   SkinCancer_Yes  \n",
       "0               1  \n",
       "1               0  \n",
       "2               0  \n",
       "3               1  \n",
       "4               0  \n",
       "\n",
       "[5 rows x 63 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = heartdisease_df.drop(labels=[\"HeartDisease\", \"heart_disease\"], axis=1)[:1000]\n",
    "X = X.dropna()\n",
    "X = pd.get_dummies(X)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BMI</th>\n",
       "      <th>PhysicalHealth</th>\n",
       "      <th>MentalHealth</th>\n",
       "      <th>SleepTime</th>\n",
       "      <th>smoking_code</th>\n",
       "      <th>alcohol_code</th>\n",
       "      <th>stroke_code</th>\n",
       "      <th>difficulty_walking_code</th>\n",
       "      <th>sex_code</th>\n",
       "      <th>age_category</th>\n",
       "      <th>...</th>\n",
       "      <th>GenHealth_Fair</th>\n",
       "      <th>GenHealth_Good</th>\n",
       "      <th>GenHealth_Poor</th>\n",
       "      <th>GenHealth_Very good</th>\n",
       "      <th>Asthma_No</th>\n",
       "      <th>Asthma_Yes</th>\n",
       "      <th>KidneyDisease_No</th>\n",
       "      <th>KidneyDisease_Yes</th>\n",
       "      <th>SkinCancer_No</th>\n",
       "      <th>SkinCancer_Yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.902797</td>\n",
       "      <td>-0.178819</td>\n",
       "      <td>3.475697</td>\n",
       "      <td>-1.362385</td>\n",
       "      <td>1.172144</td>\n",
       "      <td>-0.178773</td>\n",
       "      <td>-0.310475</td>\n",
       "      <td>-0.615574</td>\n",
       "      <td>-0.704634</td>\n",
       "      <td>-0.908545</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.474621</td>\n",
       "      <td>-0.730211</td>\n",
       "      <td>-0.290713</td>\n",
       "      <td>1.602765</td>\n",
       "      <td>-2.436904</td>\n",
       "      <td>2.436904</td>\n",
       "      <td>0.272102</td>\n",
       "      <td>-0.272102</td>\n",
       "      <td>-2.063709</td>\n",
       "      <td>2.063709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.334008</td>\n",
       "      <td>-0.509150</td>\n",
       "      <td>-0.431922</td>\n",
       "      <td>-0.147055</td>\n",
       "      <td>-0.852284</td>\n",
       "      <td>-0.178773</td>\n",
       "      <td>3.217650</td>\n",
       "      <td>-0.615574</td>\n",
       "      <td>-0.704634</td>\n",
       "      <td>1.150714</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.474621</td>\n",
       "      <td>-0.730211</td>\n",
       "      <td>-0.290713</td>\n",
       "      <td>1.602765</td>\n",
       "      <td>0.409946</td>\n",
       "      <td>-0.409946</td>\n",
       "      <td>0.272102</td>\n",
       "      <td>-0.272102</td>\n",
       "      <td>0.484080</td>\n",
       "      <td>-0.484080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.385011</td>\n",
       "      <td>1.693056</td>\n",
       "      <td>3.475697</td>\n",
       "      <td>0.460610</td>\n",
       "      <td>1.172144</td>\n",
       "      <td>-0.178773</td>\n",
       "      <td>-0.310475</td>\n",
       "      <td>-0.615574</td>\n",
       "      <td>1.417757</td>\n",
       "      <td>-0.084842</td>\n",
       "      <td>...</td>\n",
       "      <td>2.104839</td>\n",
       "      <td>-0.730211</td>\n",
       "      <td>-0.290713</td>\n",
       "      <td>-0.623298</td>\n",
       "      <td>-2.436904</td>\n",
       "      <td>2.436904</td>\n",
       "      <td>0.272102</td>\n",
       "      <td>-0.272102</td>\n",
       "      <td>0.484080</td>\n",
       "      <td>-0.484080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.745447</td>\n",
       "      <td>-0.509150</td>\n",
       "      <td>-0.431922</td>\n",
       "      <td>-0.754720</td>\n",
       "      <td>-0.852284</td>\n",
       "      <td>-0.178773</td>\n",
       "      <td>-0.310475</td>\n",
       "      <td>-0.615574</td>\n",
       "      <td>-0.704634</td>\n",
       "      <td>0.738862</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.474621</td>\n",
       "      <td>1.368097</td>\n",
       "      <td>-0.290713</td>\n",
       "      <td>-0.623298</td>\n",
       "      <td>0.409946</td>\n",
       "      <td>-0.409946</td>\n",
       "      <td>0.272102</td>\n",
       "      <td>-0.272102</td>\n",
       "      <td>-2.063709</td>\n",
       "      <td>2.063709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.821489</td>\n",
       "      <td>2.573939</td>\n",
       "      <td>-0.431922</td>\n",
       "      <td>0.460610</td>\n",
       "      <td>-0.852284</td>\n",
       "      <td>-0.178773</td>\n",
       "      <td>-0.310475</td>\n",
       "      <td>1.622876</td>\n",
       "      <td>-0.704634</td>\n",
       "      <td>-2.144101</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.474621</td>\n",
       "      <td>-0.730211</td>\n",
       "      <td>-0.290713</td>\n",
       "      <td>1.602765</td>\n",
       "      <td>0.409946</td>\n",
       "      <td>-0.409946</td>\n",
       "      <td>0.272102</td>\n",
       "      <td>-0.272102</td>\n",
       "      <td>0.484080</td>\n",
       "      <td>-0.484080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>-0.124950</td>\n",
       "      <td>0.591953</td>\n",
       "      <td>2.173157</td>\n",
       "      <td>0.460610</td>\n",
       "      <td>1.172144</td>\n",
       "      <td>-0.178773</td>\n",
       "      <td>-0.310475</td>\n",
       "      <td>-0.615574</td>\n",
       "      <td>-0.704634</td>\n",
       "      <td>-0.084842</td>\n",
       "      <td>...</td>\n",
       "      <td>2.104839</td>\n",
       "      <td>-0.730211</td>\n",
       "      <td>-0.290713</td>\n",
       "      <td>-0.623298</td>\n",
       "      <td>0.409946</td>\n",
       "      <td>-0.409946</td>\n",
       "      <td>0.272102</td>\n",
       "      <td>-0.272102</td>\n",
       "      <td>0.484080</td>\n",
       "      <td>-0.484080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>-0.520365</td>\n",
       "      <td>-0.509150</td>\n",
       "      <td>-0.431922</td>\n",
       "      <td>0.460610</td>\n",
       "      <td>1.172144</td>\n",
       "      <td>-0.178773</td>\n",
       "      <td>-0.310475</td>\n",
       "      <td>-0.615574</td>\n",
       "      <td>-0.704634</td>\n",
       "      <td>0.738862</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.474621</td>\n",
       "      <td>-0.730211</td>\n",
       "      <td>-0.290713</td>\n",
       "      <td>-0.623298</td>\n",
       "      <td>0.409946</td>\n",
       "      <td>-0.409946</td>\n",
       "      <td>0.272102</td>\n",
       "      <td>-0.272102</td>\n",
       "      <td>0.484080</td>\n",
       "      <td>-0.484080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>-0.322657</td>\n",
       "      <td>-0.399040</td>\n",
       "      <td>-0.431922</td>\n",
       "      <td>0.460610</td>\n",
       "      <td>-0.852284</td>\n",
       "      <td>-0.178773</td>\n",
       "      <td>-0.310475</td>\n",
       "      <td>-0.615574</td>\n",
       "      <td>1.417757</td>\n",
       "      <td>0.327010</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.474621</td>\n",
       "      <td>-0.730211</td>\n",
       "      <td>-0.290713</td>\n",
       "      <td>1.602765</td>\n",
       "      <td>0.409946</td>\n",
       "      <td>-0.409946</td>\n",
       "      <td>0.272102</td>\n",
       "      <td>-0.272102</td>\n",
       "      <td>0.484080</td>\n",
       "      <td>-0.484080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>2.308374</td>\n",
       "      <td>2.794160</td>\n",
       "      <td>-0.431922</td>\n",
       "      <td>-0.754720</td>\n",
       "      <td>-0.852284</td>\n",
       "      <td>-0.178773</td>\n",
       "      <td>-0.310475</td>\n",
       "      <td>1.622876</td>\n",
       "      <td>-0.704634</td>\n",
       "      <td>0.327010</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.474621</td>\n",
       "      <td>1.368097</td>\n",
       "      <td>-0.290713</td>\n",
       "      <td>-0.623298</td>\n",
       "      <td>-2.436904</td>\n",
       "      <td>2.436904</td>\n",
       "      <td>0.272102</td>\n",
       "      <td>-0.272102</td>\n",
       "      <td>0.484080</td>\n",
       "      <td>-0.484080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>-0.499073</td>\n",
       "      <td>-0.509150</td>\n",
       "      <td>-0.431922</td>\n",
       "      <td>-0.147055</td>\n",
       "      <td>-0.852284</td>\n",
       "      <td>-0.178773</td>\n",
       "      <td>-0.310475</td>\n",
       "      <td>-0.615574</td>\n",
       "      <td>1.417757</td>\n",
       "      <td>0.327010</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.474621</td>\n",
       "      <td>-0.730211</td>\n",
       "      <td>-0.290713</td>\n",
       "      <td>-0.623298</td>\n",
       "      <td>0.409946</td>\n",
       "      <td>-0.409946</td>\n",
       "      <td>0.272102</td>\n",
       "      <td>-0.272102</td>\n",
       "      <td>0.484080</td>\n",
       "      <td>-0.484080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          BMI  PhysicalHealth  MentalHealth  SleepTime  smoking_code  \\\n",
       "0   -1.902797       -0.178819      3.475697  -1.362385      1.172144   \n",
       "1   -1.334008       -0.509150     -0.431922  -0.147055     -0.852284   \n",
       "2   -0.385011        1.693056      3.475697   0.460610      1.172144   \n",
       "3   -0.745447       -0.509150     -0.431922  -0.754720     -0.852284   \n",
       "4   -0.821489        2.573939     -0.431922   0.460610     -0.852284   \n",
       "..        ...             ...           ...        ...           ...   \n",
       "995 -0.124950        0.591953      2.173157   0.460610      1.172144   \n",
       "996 -0.520365       -0.509150     -0.431922   0.460610      1.172144   \n",
       "997 -0.322657       -0.399040     -0.431922   0.460610     -0.852284   \n",
       "998  2.308374        2.794160     -0.431922  -0.754720     -0.852284   \n",
       "999 -0.499073       -0.509150     -0.431922  -0.147055     -0.852284   \n",
       "\n",
       "     alcohol_code  stroke_code  difficulty_walking_code  sex_code  \\\n",
       "0       -0.178773    -0.310475                -0.615574 -0.704634   \n",
       "1       -0.178773     3.217650                -0.615574 -0.704634   \n",
       "2       -0.178773    -0.310475                -0.615574  1.417757   \n",
       "3       -0.178773    -0.310475                -0.615574 -0.704634   \n",
       "4       -0.178773    -0.310475                 1.622876 -0.704634   \n",
       "..            ...          ...                      ...       ...   \n",
       "995     -0.178773    -0.310475                -0.615574 -0.704634   \n",
       "996     -0.178773    -0.310475                -0.615574 -0.704634   \n",
       "997     -0.178773    -0.310475                -0.615574  1.417757   \n",
       "998     -0.178773    -0.310475                 1.622876 -0.704634   \n",
       "999     -0.178773    -0.310475                -0.615574  1.417757   \n",
       "\n",
       "     age_category  ...  GenHealth_Fair  GenHealth_Good  GenHealth_Poor  \\\n",
       "0       -0.908545  ...       -0.474621       -0.730211       -0.290713   \n",
       "1        1.150714  ...       -0.474621       -0.730211       -0.290713   \n",
       "2       -0.084842  ...        2.104839       -0.730211       -0.290713   \n",
       "3        0.738862  ...       -0.474621        1.368097       -0.290713   \n",
       "4       -2.144101  ...       -0.474621       -0.730211       -0.290713   \n",
       "..            ...  ...             ...             ...             ...   \n",
       "995     -0.084842  ...        2.104839       -0.730211       -0.290713   \n",
       "996      0.738862  ...       -0.474621       -0.730211       -0.290713   \n",
       "997      0.327010  ...       -0.474621       -0.730211       -0.290713   \n",
       "998      0.327010  ...       -0.474621        1.368097       -0.290713   \n",
       "999      0.327010  ...       -0.474621       -0.730211       -0.290713   \n",
       "\n",
       "     GenHealth_Very good  Asthma_No  Asthma_Yes  KidneyDisease_No  \\\n",
       "0               1.602765  -2.436904    2.436904          0.272102   \n",
       "1               1.602765   0.409946   -0.409946          0.272102   \n",
       "2              -0.623298  -2.436904    2.436904          0.272102   \n",
       "3              -0.623298   0.409946   -0.409946          0.272102   \n",
       "4               1.602765   0.409946   -0.409946          0.272102   \n",
       "..                   ...        ...         ...               ...   \n",
       "995            -0.623298   0.409946   -0.409946          0.272102   \n",
       "996            -0.623298   0.409946   -0.409946          0.272102   \n",
       "997             1.602765   0.409946   -0.409946          0.272102   \n",
       "998            -0.623298  -2.436904    2.436904          0.272102   \n",
       "999            -0.623298   0.409946   -0.409946          0.272102   \n",
       "\n",
       "     KidneyDisease_Yes  SkinCancer_No  SkinCancer_Yes  \n",
       "0            -0.272102      -2.063709        2.063709  \n",
       "1            -0.272102       0.484080       -0.484080  \n",
       "2            -0.272102       0.484080       -0.484080  \n",
       "3            -0.272102      -2.063709        2.063709  \n",
       "4            -0.272102       0.484080       -0.484080  \n",
       "..                 ...            ...             ...  \n",
       "995          -0.272102       0.484080       -0.484080  \n",
       "996          -0.272102       0.484080       -0.484080  \n",
       "997          -0.272102       0.484080       -0.484080  \n",
       "998          -0.272102       0.484080       -0.484080  \n",
       "999          -0.272102       0.484080       -0.484080  \n",
       "\n",
       "[1000 rows x 63 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standard scaling\n",
    "means = X.mean()\n",
    "sds = X.std()\n",
    "X2 = X.apply(lambda x: (x-means)/sds,axis=1)\n",
    "X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    849\n",
       "1    151\n",
       "Name: heart_disease, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = heartdisease_df.loc[X2.index,'heart_disease']\n",
    "t.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 1\n",
    "In your own words, describe the preprocessing steps I took above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your solution here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the network\n",
    "We are now going to train the network. We'll use the defaults that I've set in the function, but feel free to change them around and see how you can do. I am going to show you how setting the seed makes a difference in training the algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_318872/3061938610.py:11: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only.\n",
      "  results = pd.concat(results,results1)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "first argument must be an iterable of pandas objects, you passed an object of type \"DataFrame\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     results \u001b[38;5;241m=\u001b[39m results1\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 11\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\u001b[43mresults1\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.9/site-packages/pandas/core/reshape/concat.py:347\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjs\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconcat\u001b[39m(\n\u001b[1;32m    145\u001b[0m     objs: Iterable[NDFrame] \u001b[38;5;241m|\u001b[39m Mapping[Hashable, NDFrame],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    154\u001b[0m     copy: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    155\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    157\u001b[0m \u001b[38;5;124;03m    Concatenate pandas objects along a particular axis with optional set logic\u001b[39;00m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;124;03m    along the other axes.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;124;03m    ValueError: Indexes have overlapping values: ['a']\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    360\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[0;32m/opt/tljh/user/lib/python3.9/site-packages/pandas/core/reshape/concat.py:382\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    368\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    369\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    370\u001b[0m     objs: Iterable[NDFrame] \u001b[38;5;241m|\u001b[39m Mapping[Hashable, NDFrame],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    379\u001b[0m     sort\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    380\u001b[0m ):\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(objs, (ABCSeries, ABCDataFrame, \u001b[38;5;28mstr\u001b[39m)):\n\u001b[0;32m--> 382\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    383\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfirst argument must be an iterable of pandas \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    384\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mobjects, you passed an object of type \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(objs)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    385\u001b[0m         )\n\u001b[1;32m    387\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m join \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mouter\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    388\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintersect \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: first argument must be an iterable of pandas objects, you passed an object of type \"DataFrame\""
     ]
    }
   ],
   "source": [
    "seeds = [0,1,2,3,4,5]\n",
    "results = None\n",
    "w = {}\n",
    "X_test = {}\n",
    "t_test = {}\n",
    "for seed in seeds:\n",
    "    w[seed],X_test[seed],t_test[seed],results1 = Lab3_helper.train(X2,t,seed=seed)\n",
    "    if results is None:\n",
    "        results = results1\n",
    "    else:\n",
    "        results = pd.concat(results,results1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'altair'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01maltair\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01malt\u001b[39;00m\n\u001b[1;32m      2\u001b[0m alt\u001b[38;5;241m.\u001b[39mdata_transformers\u001b[38;5;241m.\u001b[39mdisable_max_rows()\n\u001b[1;32m      4\u001b[0m source \u001b[38;5;241m=\u001b[39m results\u001b[38;5;241m.\u001b[39mreset_index()\u001b[38;5;241m.\u001b[39mdrop([\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mn\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest_size\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_size\u001b[39m\u001b[38;5;124m'\u001b[39m],axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mmelt(id_vars\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepoch\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mseed\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'altair'"
     ]
    }
   ],
   "source": [
    "import altair as alt\n",
    "alt.data_transformers.disable_max_rows()\n",
    "\n",
    "source = results.reset_index().drop(['n','test_size','val_size'],axis=1).melt(id_vars=['epoch','seed'])\n",
    "\n",
    "alt.Chart(source).mark_line().encode(\n",
    "    x='epoch',\n",
    "    y=alt.Y('value',title='Accuracy'),\n",
    "    color='variable',\n",
    "    column='seed'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 2\n",
    "Run a similar experiment but vary the learning rate as below. Keep the seed constant (seed=0). What do the graphs tell you about the parameter ``n`` (i.e., $\\eta$)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n_/vkzqctrn6pncgk9fpmhybzw40000gn/T/ipykernel_6479/469557475.py:9: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append(results1)\n"
     ]
    }
   ],
   "source": [
    "ns = [0.01,0.1]\n",
    "results = None\n",
    "# Your solution here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-f03748369a6a409292fa7345899fee9c\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-f03748369a6a409292fa7345899fee9c\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-f03748369a6a409292fa7345899fee9c\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-a579392de8c43aa476877a71948efe67\"}, \"mark\": \"line\", \"encoding\": {\"color\": {\"field\": \"variable\", \"type\": \"nominal\"}, \"column\": {\"field\": \"n\", \"type\": \"quantitative\"}, \"x\": {\"field\": \"epoch\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"value\", \"title\": \"Accuracy\", \"type\": \"quantitative\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-a579392de8c43aa476877a71948efe67\": [{\"epoch\": 1, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.4673469387755102}, {\"epoch\": 2, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.49387755102040815}, {\"epoch\": 3, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.5081632653061224}, {\"epoch\": 4, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.5183673469387755}, {\"epoch\": 5, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.5306122448979592}, {\"epoch\": 6, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.5489795918367347}, {\"epoch\": 7, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.6}, {\"epoch\": 8, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.6163265306122448}, {\"epoch\": 9, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.6326530612244898}, {\"epoch\": 10, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.6510204081632653}, {\"epoch\": 11, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.6551020408163265}, {\"epoch\": 12, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.6673469387755102}, {\"epoch\": 13, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.689795918367347}, {\"epoch\": 14, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.7020408163265306}, {\"epoch\": 15, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.7204081632653061}, {\"epoch\": 16, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.7408163265306122}, {\"epoch\": 17, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.7571428571428571}, {\"epoch\": 18, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.763265306122449}, {\"epoch\": 19, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.7653061224489796}, {\"epoch\": 20, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.7714285714285715}, {\"epoch\": 21, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.7795918367346939}, {\"epoch\": 22, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.7918367346938775}, {\"epoch\": 23, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8}, {\"epoch\": 24, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8}, {\"epoch\": 25, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8040816326530612}, {\"epoch\": 26, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8061224489795918}, {\"epoch\": 27, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8081632653061225}, {\"epoch\": 28, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8081632653061225}, {\"epoch\": 29, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8040816326530612}, {\"epoch\": 30, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8040816326530612}, {\"epoch\": 31, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.810204081632653}, {\"epoch\": 32, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.810204081632653}, {\"epoch\": 33, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.810204081632653}, {\"epoch\": 34, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8142857142857143}, {\"epoch\": 35, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8142857142857143}, {\"epoch\": 36, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8163265306122449}, {\"epoch\": 37, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8183673469387756}, {\"epoch\": 38, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8204081632653061}, {\"epoch\": 39, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8204081632653061}, {\"epoch\": 40, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8224489795918367}, {\"epoch\": 41, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8224489795918367}, {\"epoch\": 42, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8244897959183674}, {\"epoch\": 43, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 44, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8285714285714286}, {\"epoch\": 45, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8285714285714286}, {\"epoch\": 46, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8285714285714286}, {\"epoch\": 47, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8326530612244898}, {\"epoch\": 48, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 49, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 50, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 51, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 52, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 53, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 54, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8285714285714286}, {\"epoch\": 55, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8285714285714286}, {\"epoch\": 56, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 57, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 58, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 59, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8285714285714286}, {\"epoch\": 60, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8285714285714286}, {\"epoch\": 61, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8285714285714286}, {\"epoch\": 62, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8285714285714286}, {\"epoch\": 63, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8285714285714286}, {\"epoch\": 64, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8285714285714286}, {\"epoch\": 65, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8285714285714286}, {\"epoch\": 66, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8285714285714286}, {\"epoch\": 67, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8285714285714286}, {\"epoch\": 68, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8285714285714286}, {\"epoch\": 69, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8285714285714286}, {\"epoch\": 70, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8285714285714286}, {\"epoch\": 71, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8285714285714286}, {\"epoch\": 72, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8285714285714286}, {\"epoch\": 73, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8285714285714286}, {\"epoch\": 74, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8285714285714286}, {\"epoch\": 75, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8285714285714286}, {\"epoch\": 76, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8285714285714286}, {\"epoch\": 77, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 78, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 79, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 80, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 81, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 82, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 83, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 84, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 85, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 86, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 87, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 88, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 89, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 90, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 91, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 92, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 93, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 94, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 95, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 96, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 97, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 98, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8285714285714286}, {\"epoch\": 99, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8285714285714286}, {\"epoch\": 100, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8285714285714286}, {\"epoch\": 101, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8285714285714286}, {\"epoch\": 102, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8285714285714286}, {\"epoch\": 103, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8285714285714286}, {\"epoch\": 104, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8285714285714286}, {\"epoch\": 105, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8285714285714286}, {\"epoch\": 106, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8285714285714286}, {\"epoch\": 107, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8285714285714286}, {\"epoch\": 108, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 109, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 110, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 111, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 112, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 113, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 114, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 115, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 116, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 117, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 118, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 119, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 120, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 121, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 122, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 123, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 124, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 125, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 126, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 127, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 128, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 129, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 130, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 131, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 132, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 133, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 134, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8285714285714286}, {\"epoch\": 135, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8285714285714286}, {\"epoch\": 136, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8285714285714286}, {\"epoch\": 137, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8285714285714286}, {\"epoch\": 138, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 139, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8326530612244898}, {\"epoch\": 140, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8326530612244898}, {\"epoch\": 141, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8326530612244898}, {\"epoch\": 142, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8326530612244898}, {\"epoch\": 143, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8326530612244898}, {\"epoch\": 144, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8326530612244898}, {\"epoch\": 145, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8326530612244898}, {\"epoch\": 146, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8326530612244898}, {\"epoch\": 147, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8326530612244898}, {\"epoch\": 148, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8326530612244898}, {\"epoch\": 149, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8326530612244898}, {\"epoch\": 150, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8326530612244898}, {\"epoch\": 151, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8326530612244898}, {\"epoch\": 152, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8326530612244898}, {\"epoch\": 153, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8326530612244898}, {\"epoch\": 154, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8326530612244898}, {\"epoch\": 155, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8326530612244898}, {\"epoch\": 156, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8326530612244898}, {\"epoch\": 157, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8326530612244898}, {\"epoch\": 158, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8326530612244898}, {\"epoch\": 159, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8326530612244898}, {\"epoch\": 160, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8326530612244898}, {\"epoch\": 161, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8326530612244898}, {\"epoch\": 162, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8326530612244898}, {\"epoch\": 163, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8326530612244898}, {\"epoch\": 164, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8326530612244898}, {\"epoch\": 165, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8326530612244898}, {\"epoch\": 166, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8326530612244898}, {\"epoch\": 167, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8326530612244898}, {\"epoch\": 168, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8326530612244898}, {\"epoch\": 169, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8326530612244898}, {\"epoch\": 170, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8326530612244898}, {\"epoch\": 171, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8326530612244898}, {\"epoch\": 172, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8326530612244898}, {\"epoch\": 173, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8326530612244898}, {\"epoch\": 174, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8326530612244898}, {\"epoch\": 175, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8326530612244898}, {\"epoch\": 176, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8326530612244898}, {\"epoch\": 177, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8326530612244898}, {\"epoch\": 178, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8326530612244898}, {\"epoch\": 179, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8326530612244898}, {\"epoch\": 180, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8326530612244898}, {\"epoch\": 181, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8326530612244898}, {\"epoch\": 182, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8326530612244898}, {\"epoch\": 183, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8326530612244898}, {\"epoch\": 184, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8326530612244898}, {\"epoch\": 185, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8326530612244898}, {\"epoch\": 186, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8326530612244898}, {\"epoch\": 187, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8326530612244898}, {\"epoch\": 188, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8326530612244898}, {\"epoch\": 189, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8326530612244898}, {\"epoch\": 190, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8326530612244898}, {\"epoch\": 191, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8326530612244898}, {\"epoch\": 192, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8326530612244898}, {\"epoch\": 193, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8326530612244898}, {\"epoch\": 194, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8326530612244898}, {\"epoch\": 195, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8326530612244898}, {\"epoch\": 196, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8326530612244898}, {\"epoch\": 197, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8326530612244898}, {\"epoch\": 198, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8326530612244898}, {\"epoch\": 199, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8326530612244898}, {\"epoch\": 200, \"n\": 0.01, \"variable\": \"train_accuracy\", \"value\": 0.8326530612244898}, {\"epoch\": 1, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.4673469387755102}, {\"epoch\": 2, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.6061224489795919}, {\"epoch\": 3, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.6612244897959184}, {\"epoch\": 4, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.7204081632653061}, {\"epoch\": 5, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.7551020408163265}, {\"epoch\": 6, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.6510204081632653}, {\"epoch\": 7, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.6775510204081633}, {\"epoch\": 8, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.7306122448979592}, {\"epoch\": 9, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.7816326530612245}, {\"epoch\": 10, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8163265306122449}, {\"epoch\": 11, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8183673469387756}, {\"epoch\": 12, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8142857142857143}, {\"epoch\": 13, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8040816326530612}, {\"epoch\": 14, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8061224489795918}, {\"epoch\": 15, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8183673469387756}, {\"epoch\": 16, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8142857142857143}, {\"epoch\": 17, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8163265306122449}, {\"epoch\": 18, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.810204081632653}, {\"epoch\": 19, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8061224489795918}, {\"epoch\": 20, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8163265306122449}, {\"epoch\": 21, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8183673469387756}, {\"epoch\": 22, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8081632653061225}, {\"epoch\": 23, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8081632653061225}, {\"epoch\": 24, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8122448979591836}, {\"epoch\": 25, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.810204081632653}, {\"epoch\": 26, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.810204081632653}, {\"epoch\": 27, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.810204081632653}, {\"epoch\": 28, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8142857142857143}, {\"epoch\": 29, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.810204081632653}, {\"epoch\": 30, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8122448979591836}, {\"epoch\": 31, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.810204081632653}, {\"epoch\": 32, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8142857142857143}, {\"epoch\": 33, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8122448979591836}, {\"epoch\": 34, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8142857142857143}, {\"epoch\": 35, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8122448979591836}, {\"epoch\": 36, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8183673469387756}, {\"epoch\": 37, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8142857142857143}, {\"epoch\": 38, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8224489795918367}, {\"epoch\": 39, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8163265306122449}, {\"epoch\": 40, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8244897959183674}, {\"epoch\": 41, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8163265306122449}, {\"epoch\": 42, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8244897959183674}, {\"epoch\": 43, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8204081632653061}, {\"epoch\": 44, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8244897959183674}, {\"epoch\": 45, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8204081632653061}, {\"epoch\": 46, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8244897959183674}, {\"epoch\": 47, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8244897959183674}, {\"epoch\": 48, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8244897959183674}, {\"epoch\": 49, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8244897959183674}, {\"epoch\": 50, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8224489795918367}, {\"epoch\": 51, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8244897959183674}, {\"epoch\": 52, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8224489795918367}, {\"epoch\": 53, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8244897959183674}, {\"epoch\": 54, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8224489795918367}, {\"epoch\": 55, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8244897959183674}, {\"epoch\": 56, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8224489795918367}, {\"epoch\": 57, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8244897959183674}, {\"epoch\": 58, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8224489795918367}, {\"epoch\": 59, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8244897959183674}, {\"epoch\": 60, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8224489795918367}, {\"epoch\": 61, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8244897959183674}, {\"epoch\": 62, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8224489795918367}, {\"epoch\": 63, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8244897959183674}, {\"epoch\": 64, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8224489795918367}, {\"epoch\": 65, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8244897959183674}, {\"epoch\": 66, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8224489795918367}, {\"epoch\": 67, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8244897959183674}, {\"epoch\": 68, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8224489795918367}, {\"epoch\": 69, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8244897959183674}, {\"epoch\": 70, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8224489795918367}, {\"epoch\": 71, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 72, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8224489795918367}, {\"epoch\": 73, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 74, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8244897959183674}, {\"epoch\": 75, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 76, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8244897959183674}, {\"epoch\": 77, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8244897959183674}, {\"epoch\": 78, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8244897959183674}, {\"epoch\": 79, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8244897959183674}, {\"epoch\": 80, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 81, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 82, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 83, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 84, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 85, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 86, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 87, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 88, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 89, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 90, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 91, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 92, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 93, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 94, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 95, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 96, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 97, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 98, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 99, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 100, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 101, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 102, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 103, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 104, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 105, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 106, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 107, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 108, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 109, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 110, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 111, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 112, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 113, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 114, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 115, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 116, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 117, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 118, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 119, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.826530612244898}, {\"epoch\": 120, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8285714285714286}, {\"epoch\": 121, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8285714285714286}, {\"epoch\": 122, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8285714285714286}, {\"epoch\": 123, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8285714285714286}, {\"epoch\": 124, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8285714285714286}, {\"epoch\": 125, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8285714285714286}, {\"epoch\": 126, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8285714285714286}, {\"epoch\": 127, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8285714285714286}, {\"epoch\": 128, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8285714285714286}, {\"epoch\": 129, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8285714285714286}, {\"epoch\": 130, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8285714285714286}, {\"epoch\": 131, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8285714285714286}, {\"epoch\": 132, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8285714285714286}, {\"epoch\": 133, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8285714285714286}, {\"epoch\": 134, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8285714285714286}, {\"epoch\": 135, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8285714285714286}, {\"epoch\": 136, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8285714285714286}, {\"epoch\": 137, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8285714285714286}, {\"epoch\": 138, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8285714285714286}, {\"epoch\": 139, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8285714285714286}, {\"epoch\": 140, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8285714285714286}, {\"epoch\": 141, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8285714285714286}, {\"epoch\": 142, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 143, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 144, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 145, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 146, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 147, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 148, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 149, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 150, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 151, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 152, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 153, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 154, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 155, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 156, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 157, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 158, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 159, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 160, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 161, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 162, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 163, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 164, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 165, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 166, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 167, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 168, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 169, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 170, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 171, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 172, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 173, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 174, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 175, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 176, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 177, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 178, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 179, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 180, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 181, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 182, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 183, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 184, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 185, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 186, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 187, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 188, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 189, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 190, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 191, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 192, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 193, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 194, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 195, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 196, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 197, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 198, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 199, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 200, \"n\": 0.1, \"variable\": \"train_accuracy\", \"value\": 0.8306122448979592}, {\"epoch\": 1, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.4238095238095238}, {\"epoch\": 2, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.4380952380952381}, {\"epoch\": 3, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.44285714285714284}, {\"epoch\": 4, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.44761904761904764}, {\"epoch\": 5, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.4666666666666667}, {\"epoch\": 6, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.4666666666666667}, {\"epoch\": 7, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.4857142857142857}, {\"epoch\": 8, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.48095238095238096}, {\"epoch\": 9, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.49047619047619045}, {\"epoch\": 10, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.5}, {\"epoch\": 11, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.5238095238095238}, {\"epoch\": 12, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.5428571428571428}, {\"epoch\": 13, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.580952380952381}, {\"epoch\": 14, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.5857142857142857}, {\"epoch\": 15, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.6}, {\"epoch\": 16, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.6190476190476191}, {\"epoch\": 17, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.6333333333333333}, {\"epoch\": 18, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.6523809523809524}, {\"epoch\": 19, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.6761904761904762}, {\"epoch\": 20, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7142857142857143}, {\"epoch\": 21, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7238095238095238}, {\"epoch\": 22, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7380952380952381}, {\"epoch\": 23, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7428571428571429}, {\"epoch\": 24, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7666666666666667}, {\"epoch\": 25, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7714285714285715}, {\"epoch\": 26, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7714285714285715}, {\"epoch\": 27, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7761904761904762}, {\"epoch\": 28, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7714285714285715}, {\"epoch\": 29, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.780952380952381}, {\"epoch\": 30, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 31, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7952380952380952}, {\"epoch\": 32, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 33, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7952380952380952}, {\"epoch\": 34, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 35, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 36, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7952380952380952}, {\"epoch\": 37, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7952380952380952}, {\"epoch\": 38, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7952380952380952}, {\"epoch\": 39, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 40, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 41, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 42, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 43, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 44, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 45, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 46, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7952380952380952}, {\"epoch\": 47, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 48, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 49, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 50, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7952380952380952}, {\"epoch\": 51, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7952380952380952}, {\"epoch\": 52, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 53, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 54, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 55, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 56, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 57, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 58, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 59, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 60, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 61, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 62, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 63, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 64, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 65, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 66, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 67, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 68, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 69, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 70, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 71, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 72, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 73, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 74, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 75, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 76, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 77, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 78, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 79, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 80, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 81, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 82, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 83, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 84, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 85, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 86, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 87, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 88, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 89, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 90, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 91, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 92, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 93, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 94, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 95, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 96, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 97, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 98, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 99, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 100, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 101, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 102, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 103, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 104, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 105, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 106, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 107, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 108, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 109, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 110, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 111, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 112, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 113, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 114, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 115, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 116, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 117, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 118, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 119, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 120, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 121, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 122, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 123, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 124, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 125, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 126, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 127, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 128, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 129, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 130, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 131, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 132, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 133, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 134, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 135, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 136, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 137, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 138, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 139, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 140, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 141, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 142, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 143, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 144, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 145, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 146, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 147, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 148, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 149, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 150, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 151, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 152, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 153, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 154, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 155, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 156, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 157, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 158, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 159, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 160, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 161, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 162, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 163, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 164, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 165, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 166, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 167, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 168, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 169, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 170, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 171, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 172, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 173, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 174, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 175, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 176, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 177, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 178, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 179, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 180, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 181, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 182, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 183, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 184, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 185, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 186, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 187, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 188, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 189, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 190, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 191, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 192, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 193, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 194, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 195, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7857142857142857}, {\"epoch\": 196, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 197, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 198, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 199, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 200, \"n\": 0.01, \"variable\": \"val_accuracy\", \"value\": 0.7904761904761904}, {\"epoch\": 1, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.4238095238095238}, {\"epoch\": 2, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.5428571428571428}, {\"epoch\": 3, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.5714285714285714}, {\"epoch\": 4, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.5857142857142857}, {\"epoch\": 5, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.6761904761904762}, {\"epoch\": 6, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.6}, {\"epoch\": 7, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.6190476190476191}, {\"epoch\": 8, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.6666666666666666}, {\"epoch\": 9, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7238095238095238}, {\"epoch\": 10, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7428571428571429}, {\"epoch\": 11, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7333333333333333}, {\"epoch\": 12, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7523809523809524}, {\"epoch\": 13, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7285714285714285}, {\"epoch\": 14, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7571428571428571}, {\"epoch\": 15, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7571428571428571}, {\"epoch\": 16, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7523809523809524}, {\"epoch\": 17, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7666666666666667}, {\"epoch\": 18, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7285714285714285}, {\"epoch\": 19, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7571428571428571}, {\"epoch\": 20, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 21, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7666666666666667}, {\"epoch\": 22, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7333333333333333}, {\"epoch\": 23, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7571428571428571}, {\"epoch\": 24, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7285714285714285}, {\"epoch\": 25, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7571428571428571}, {\"epoch\": 26, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7285714285714285}, {\"epoch\": 27, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7619047619047619}, {\"epoch\": 28, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7285714285714285}, {\"epoch\": 29, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7619047619047619}, {\"epoch\": 30, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7285714285714285}, {\"epoch\": 31, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7619047619047619}, {\"epoch\": 32, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7333333333333333}, {\"epoch\": 33, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7619047619047619}, {\"epoch\": 34, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7285714285714285}, {\"epoch\": 35, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7571428571428571}, {\"epoch\": 36, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7285714285714285}, {\"epoch\": 37, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7571428571428571}, {\"epoch\": 38, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7285714285714285}, {\"epoch\": 39, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7523809523809524}, {\"epoch\": 40, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7333333333333333}, {\"epoch\": 41, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7523809523809524}, {\"epoch\": 42, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7380952380952381}, {\"epoch\": 43, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7523809523809524}, {\"epoch\": 44, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7333333333333333}, {\"epoch\": 45, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7571428571428571}, {\"epoch\": 46, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7333333333333333}, {\"epoch\": 47, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7571428571428571}, {\"epoch\": 48, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7333333333333333}, {\"epoch\": 49, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7571428571428571}, {\"epoch\": 50, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7333333333333333}, {\"epoch\": 51, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7523809523809524}, {\"epoch\": 52, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7380952380952381}, {\"epoch\": 53, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7523809523809524}, {\"epoch\": 54, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7428571428571429}, {\"epoch\": 55, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7523809523809524}, {\"epoch\": 56, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7428571428571429}, {\"epoch\": 57, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7523809523809524}, {\"epoch\": 58, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7428571428571429}, {\"epoch\": 59, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7523809523809524}, {\"epoch\": 60, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7428571428571429}, {\"epoch\": 61, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7523809523809524}, {\"epoch\": 62, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7428571428571429}, {\"epoch\": 63, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7523809523809524}, {\"epoch\": 64, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7428571428571429}, {\"epoch\": 65, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7523809523809524}, {\"epoch\": 66, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7428571428571429}, {\"epoch\": 67, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7523809523809524}, {\"epoch\": 68, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7428571428571429}, {\"epoch\": 69, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7571428571428571}, {\"epoch\": 70, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 71, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7571428571428571}, {\"epoch\": 72, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 73, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7523809523809524}, {\"epoch\": 74, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 75, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7523809523809524}, {\"epoch\": 76, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 77, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7523809523809524}, {\"epoch\": 78, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 79, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7523809523809524}, {\"epoch\": 80, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7523809523809524}, {\"epoch\": 81, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7523809523809524}, {\"epoch\": 82, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7523809523809524}, {\"epoch\": 83, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7523809523809524}, {\"epoch\": 84, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7523809523809524}, {\"epoch\": 85, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7523809523809524}, {\"epoch\": 86, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7523809523809524}, {\"epoch\": 87, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7523809523809524}, {\"epoch\": 88, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7523809523809524}, {\"epoch\": 89, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7523809523809524}, {\"epoch\": 90, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7523809523809524}, {\"epoch\": 91, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7523809523809524}, {\"epoch\": 92, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7523809523809524}, {\"epoch\": 93, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7523809523809524}, {\"epoch\": 94, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7523809523809524}, {\"epoch\": 95, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7523809523809524}, {\"epoch\": 96, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 97, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 98, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 99, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 100, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 101, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 102, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 103, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 104, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 105, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 106, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 107, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 108, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 109, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 110, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 111, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 112, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 113, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 114, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 115, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 116, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 117, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 118, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 119, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 120, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 121, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 122, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 123, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 124, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 125, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 126, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 127, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 128, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 129, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 130, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 131, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 132, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 133, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 134, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 135, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 136, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 137, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 138, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 139, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 140, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 141, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 142, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 143, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 144, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 145, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 146, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 147, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 148, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 149, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 150, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 151, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 152, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 153, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 154, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 155, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 156, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 157, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 158, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 159, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 160, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 161, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 162, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 163, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 164, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 165, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 166, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 167, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 168, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 169, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 170, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 171, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 172, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 173, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 174, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 175, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 176, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 177, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 178, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 179, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 180, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 181, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 182, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 183, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 184, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 185, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 186, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 187, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 188, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 189, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7476190476190476}, {\"epoch\": 190, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7523809523809524}, {\"epoch\": 191, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7523809523809524}, {\"epoch\": 192, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7523809523809524}, {\"epoch\": 193, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7523809523809524}, {\"epoch\": 194, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7523809523809524}, {\"epoch\": 195, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7523809523809524}, {\"epoch\": 196, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7523809523809524}, {\"epoch\": 197, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7523809523809524}, {\"epoch\": 198, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7523809523809524}, {\"epoch\": 199, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7523809523809524}, {\"epoch\": 200, \"n\": 0.1, \"variable\": \"val_accuracy\", \"value\": 0.7523809523809524}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source = results.reset_index().drop(['seed','test_size','val_size'],axis=1).melt(id_vars=['epoch','n'])\n",
    "\n",
    "alt.Chart(source).mark_line().encode(\n",
    "    x='epoch',\n",
    "    y=alt.Y('value',title='Accuracy'),\n",
    "    color='variable',\n",
    "    column='n'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 1\n",
    "The first step to evaluating any classification problem is establishing a baseline. Write a function that calculates the baseline accuracy if you predict the majority class on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n_/vkzqctrn6pncgk9fpmhybzw40000gn/T/ipykernel_6479/3268240859.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append(pd.Series([frac_max_class,accuracy_test,accuracy_train2,accuracy_val],index=results.columns,name=seed))\n",
      "/var/folders/n_/vkzqctrn6pncgk9fpmhybzw40000gn/T/ipykernel_6479/3268240859.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append(pd.Series([frac_max_class,accuracy_test,accuracy_train2,accuracy_val],index=results.columns,name=seed))\n",
      "/var/folders/n_/vkzqctrn6pncgk9fpmhybzw40000gn/T/ipykernel_6479/3268240859.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append(pd.Series([frac_max_class,accuracy_test,accuracy_train2,accuracy_val],index=results.columns,name=seed))\n",
      "/var/folders/n_/vkzqctrn6pncgk9fpmhybzw40000gn/T/ipykernel_6479/3268240859.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append(pd.Series([frac_max_class,accuracy_test,accuracy_train2,accuracy_val],index=results.columns,name=seed))\n",
      "/var/folders/n_/vkzqctrn6pncgk9fpmhybzw40000gn/T/ipykernel_6479/3268240859.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append(pd.Series([frac_max_class,accuracy_test,accuracy_train2,accuracy_val],index=results.columns,name=seed))\n",
      "/var/folders/n_/vkzqctrn6pncgk9fpmhybzw40000gn/T/ipykernel_6479/3268240859.py:14: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  results = results.append(pd.Series([frac_max_class,accuracy_test,accuracy_train2,accuracy_val],index=results.columns,name=seed))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>frac_max_class</th>\n",
       "      <th>accuracy_test</th>\n",
       "      <th>accuracy_train2</th>\n",
       "      <th>accuracy_val</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seed</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.846939</td>\n",
       "      <td>0.826667</td>\n",
       "      <td>0.846939</td>\n",
       "      <td>0.885714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.844898</td>\n",
       "      <td>0.843333</td>\n",
       "      <td>0.844898</td>\n",
       "      <td>0.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.838776</td>\n",
       "      <td>0.856667</td>\n",
       "      <td>0.838776</td>\n",
       "      <td>0.861905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.834694</td>\n",
       "      <td>0.846667</td>\n",
       "      <td>0.834694</td>\n",
       "      <td>0.885714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.84898</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.84898</td>\n",
       "      <td>0.847619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.803333</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.895238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     frac_max_class accuracy_test accuracy_train2 accuracy_val\n",
       "seed                                                          \n",
       "0          0.846939      0.826667        0.846939     0.885714\n",
       "1          0.844898      0.843333        0.844898     0.866667\n",
       "2          0.838776      0.856667        0.838776     0.861905\n",
       "3          0.834694      0.846667        0.834694     0.885714\n",
       "4           0.84898          0.85         0.84898     0.847619\n",
       "5          0.857143      0.803333        0.857143     0.895238"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "seeds = [0,1,2,3,4,5]\n",
    "results = pd.DataFrame(columns=[\"seed\",\"frac_max_class\",\"accuracy_test\",\"accuracy_train2\",\"accuracy_val\"]).set_index(\"seed\")\n",
    "for seed in seeds:\n",
    "    np.random.seed(seed)\n",
    "    X_train, X_test, t_train, t_test = train_test_split(X2, t, test_size=0.3)\n",
    "    X_train2, X_val, t_train2, t_val = train_test_split(X_train, t_train, test_size=0.3)\n",
    "\n",
    "    ## Your solution in evaluate_baseline(...)\n",
    "    frac_max_class,accuracy_test,accuracy_train2,accuracy_val = Lab3_helper.evaluate_baseline(t_test,t_train2,t_val)\n",
    "    \n",
    "    results = results.append(pd.Series([frac_max_class,accuracy_test,accuracy_train2,accuracy_val],index=results.columns,name=seed))\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<div id=\"altair-viz-4c11ec643bb14f2f9bfbfe7daeb70e9e\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-4c11ec643bb14f2f9bfbfe7daeb70e9e\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-4c11ec643bb14f2f9bfbfe7daeb70e9e\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm//vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm//vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm//vega-lite@4.17.0?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm//vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"4.17.0\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 400, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-9a7039c667a1c00644072af21cac4495\"}, \"mark\": \"boxplot\", \"encoding\": {\"x\": {\"field\": \"variable\", \"type\": \"nominal\"}, \"y\": {\"field\": \"value\", \"scale\": {\"domain\": [0.5, 0.7]}, \"type\": \"quantitative\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v4.17.0.json\", \"datasets\": {\"data-9a7039c667a1c00644072af21cac4495\": [{\"variable\": \"frac_max_class\", \"value\": 0.8469387755102041}, {\"variable\": \"frac_max_class\", \"value\": 0.8448979591836735}, {\"variable\": \"frac_max_class\", \"value\": 0.8387755102040816}, {\"variable\": \"frac_max_class\", \"value\": 0.8346938775510204}, {\"variable\": \"frac_max_class\", \"value\": 0.8489795918367347}, {\"variable\": \"frac_max_class\", \"value\": 0.8571428571428571}, {\"variable\": \"accuracy_test\", \"value\": 0.8266666666666667}, {\"variable\": \"accuracy_test\", \"value\": 0.8433333333333334}, {\"variable\": \"accuracy_test\", \"value\": 0.8566666666666667}, {\"variable\": \"accuracy_test\", \"value\": 0.8466666666666667}, {\"variable\": \"accuracy_test\", \"value\": 0.85}, {\"variable\": \"accuracy_test\", \"value\": 0.8033333333333333}, {\"variable\": \"accuracy_train2\", \"value\": 0.8469387755102041}, {\"variable\": \"accuracy_train2\", \"value\": 0.8448979591836735}, {\"variable\": \"accuracy_train2\", \"value\": 0.8387755102040816}, {\"variable\": \"accuracy_train2\", \"value\": 0.8346938775510204}, {\"variable\": \"accuracy_train2\", \"value\": 0.8489795918367347}, {\"variable\": \"accuracy_train2\", \"value\": 0.8571428571428571}, {\"variable\": \"accuracy_val\", \"value\": 0.8857142857142857}, {\"variable\": \"accuracy_val\", \"value\": 0.8666666666666667}, {\"variable\": \"accuracy_val\", \"value\": 0.861904761904762}, {\"variable\": \"accuracy_val\", \"value\": 0.8857142857142857}, {\"variable\": \"accuracy_val\", \"value\": 0.8476190476190476}, {\"variable\": \"accuracy_val\", \"value\": 0.8952380952380953}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import altair as alt\n",
    "\n",
    "source = results.melt()\n",
    "\n",
    "alt.Chart(source).mark_boxplot().encode(\n",
    "    x='variable:N',\n",
    "    y=alt.Y('value:Q',scale=alt.Scale(domain=(0.5, 0.7)))\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 2\n",
    "Write a function that makes predictions for an X matrix using the weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "993    0\n",
       "859    0\n",
       "298    0\n",
       "553    0\n",
       "672    0\n",
       "      ..\n",
       "167    0\n",
       "998    0\n",
       "984    0\n",
       "491    0\n",
       "10     0\n",
       "Length: 300, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w,X_test,t_test,results = Lab3_helper.train(X2,t,seed=0)\n",
    "\n",
    "y_test = Lab3_helper.predict(w,X_test)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 3\n",
    "Write a function that calculates the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>212</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0   1\n",
       "0  212  36\n",
       "1   30  22"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = Lab3_helper.predict(w,X_test)\n",
    "\n",
    "cm = Lab3_helper.confusion_matrix(t_test,y_test,labels=[0,1])\n",
    "cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 4\n",
    "Sensitivity, recall, hit rate, or true positive rate (TPR)\n",
    "\n",
    "${\\displaystyle \\mathrm {TPR} ={\\frac {\\mathrm {TP} }{\\mathrm {P} }}={\\frac {\\mathrm {TP} }{\\mathrm {TP} +\\mathrm {FN} }}=1-\\mathrm {FNR} }$\n",
    "\n",
    "specificity, selectivity or true negative rate (TNR)\n",
    "\n",
    "${\\displaystyle \\mathrm {TNR} ={\\frac {\\mathrm {TN} }{\\mathrm {N} }}={\\frac {\\mathrm {TN} }{\\mathrm {TN} +\\mathrm {FP} }}=1-\\mathrm {FPR} }$\n",
    "\n",
    "precision or positive predictive value (PPV)\n",
    "\n",
    "${\\displaystyle \\mathrm {PPV} ={\\frac {\\mathrm {TP} }{\\mathrm {TP} +\\mathrm {FP} }}=1-\\mathrm {FDR} }$\n",
    "\n",
    "F1\n",
    "\n",
    "${\\displaystyle F_{1}={\\frac {2}{\\mathrm {recall^{-1}} +\\mathrm {precision^{-1}} }}=2\\cdot {\\frac {\\mathrm {precision} \\cdot \\mathrm {recall} }{\\mathrm {precision} +\\mathrm {recall} }}={\\frac {\\mathrm {tp} }{\\mathrm {tp} +{\\frac {1}{2}}(\\mathrm {fp} +\\mathrm {fn} )}}}$\n",
    "\n",
    "Write a function that calculates accuracy, sensitivity/recall, specificity, precision, and F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.78,\n",
       " 'sensitivity/recall': 0.4230769230769231,\n",
       " 'specificity': 0.8548387096774194,\n",
       " 'precision': 0.3793103448275862,\n",
       " 'F1': 0.4}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = Lab3_helper.evaluation(cm,positive_class=1)\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.78,\n",
       " 'sensitivity/recall': 0.8548387096774194,\n",
       " 'specificity': 0.4230769230769231,\n",
       " 'precision': 0.8760330578512396,\n",
       " 'F1': 0.8653061224489798}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats = Lab3_helper.evaluation(cm,positive_class=0)\n",
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise 5\n",
    "Create a function that trains our neural network for each of the seeds and then returns variable importance of each feature as:\n",
    "\n",
    "${\\it importance}(w_i) = \\frac{1}{|seeds|}\\sum_{s \\in seeds} \\frac{\\sqrt{w_i^2}}{max\\left(\\sqrt{w_0^2}, \\sqrt{w_1^2} ... \\sqrt{w_d^2}\\right)}$\n",
    "\n",
    "Basically, compute the variable importance for each seed and then average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Stroke_No                 0.635591\n",
       "Stroke_Yes                0.618296\n",
       "stroke_code               0.604694\n",
       "GenHealth_Poor            0.517772\n",
       "KidneyDisease_Yes         0.448026\n",
       "                            ...   \n",
       "AgeCategory_18-24         0.033760\n",
       "Smoking_Yes               0.031648\n",
       "physical_activity_code    0.024702\n",
       "Race_Asian                0.024032\n",
       "AgeCategory_35-39         0.016837\n",
       "Length: 63, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seeds = [0,1,2,3,4,5]\n",
    "importances = Lab3_helper.importance(X2,t,seeds)\n",
    "importances.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problem 3: Compare these variable importances to the variable importances achieved by test-based permutation and train-based variable importances. \n",
    "\n",
    "To complete this problem, you will have to copy your previous lab's solutions to this notebook or Lab3_helper.py. From there, you can make the modifications necessary to train and evaluate the neural network instead of the Bayesian classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your interpretation here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Good job!\n",
    "# Don't forget to push with ./submit.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Having trouble with the test cases and the autograder?\n",
    "\n",
    "You can always load up the answers for the autograder. The autograder runs your code and compares your answer to the expected answer. I manually review your code, so there is no need to hide this from you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['exercise_1', 'exercise_2', 'exercise_3', 'exercise_4', 'exercise_5'])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "answers = joblib.load(f\"{home}/csc-466-student/tests/answers_Lab3.joblib\")\n",
    "answers.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "423    1\n",
       "177    1\n",
       "305    1\n",
       "292    0\n",
       "889    0\n",
       "      ..\n",
       "203    0\n",
       "499    0\n",
       "628    0\n",
       "879    1\n",
       "745    0\n",
       "Length: 215, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers['exercise_2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
